#!/usr/bin/env python3
# ç›´è§‚è¯„åˆ†æŸ¥çœ‹å™¨ - æä¾›æ¸…æ™°çš„è¯„åˆ†æ€»ç»“

import pandas as pd
import sys
from pathlib import Path

def calculate_overall_score(scores):
    """è®¡ç®—æ€»ä½“è¯„åˆ†"""
    valid_scores = [s for s in scores if s is not None and pd.notna(s)]
    if not valid_scores:
        return None
    return sum(valid_scores) / len(valid_scores)

def get_score_grade(score):
    """è·å–è¯„åˆ†ç­‰çº§"""
    if score is None:
        return "âŒ æœªè¯„ä»·"
    elif score >= 0.9:
        return "ğŸ† ä¼˜ç§€"
    elif score >= 0.8:
        return "ğŸ¥‡ è‰¯å¥½"
    elif score >= 0.7:
        return "ğŸ¥ˆ ä¸­ç­‰"
    elif score >= 0.6:
        return "ğŸ¥‰ åŠæ ¼"
    else:
        return "âŒ éœ€æ”¹è¿›"

def view_scores(csv_file):
    """æŸ¥çœ‹è¯„åˆ†ç»“æœ"""
    if not Path(csv_file).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
        return
    
    df = pd.read_csv(csv_file)
    
    print("ğŸ¯ RAGç³»ç»Ÿè¯„ä»·ç»“æœæ€»è§ˆ")
    print("=" * 60)
    
    # è¯†åˆ«RAGç³»ç»Ÿ
    rag_systems = []
    for col in df.columns:
        if col.endswith('_answer'):
            system_name = col.replace('_answer', '')
            rag_systems.append(system_name)
    
    # è¯†åˆ«è¯„ä»·å™¨
    evaluators = set()
    for col in df.columns:
        for system in rag_systems:
            if col.startswith(f"{system}_") and not col.endswith('_answer'):
                parts = col.replace(f"{system}_", "").split('_')
                if len(parts) >= 2:
                    evaluator = parts[0]
                    evaluators.add(evaluator)
    
    evaluators = sorted(list(evaluators))
    
    print(f"ğŸ“Š RAGç³»ç»Ÿ: {', '.join(rag_systems)}")
    print(f"ğŸ” è¯„ä»·å™¨: {', '.join(evaluators)}")
    print(f"â“ æµ‹è¯•é—®é¢˜æ•°: {len(df)}")
    print()
    
    # ä¸ºæ¯ä¸ªRAGç³»ç»Ÿæ˜¾ç¤ºè¯„åˆ†
    for system in rag_systems:
        print(f"ğŸ”µ {system.upper()} ç³»ç»Ÿè¯„ä»·")
        print("-" * 40)
        
        system_scores = {}
        
        # æ”¶é›†è¯¥ç³»ç»Ÿçš„æ‰€æœ‰è¯„åˆ†
        for evaluator in evaluators:
            evaluator_scores = {}
            
            for col in df.columns:
                if col.startswith(f"{system}_{evaluator}_"):
                    metric = col.replace(f"{system}_{evaluator}_", "")
                    scores = df[col].tolist()
                    avg_score = calculate_overall_score(scores)
                    evaluator_scores[metric] = avg_score
            
            if evaluator_scores:
                system_scores[evaluator] = evaluator_scores
        
        # æ˜¾ç¤ºè¯„åˆ†
        for evaluator, metrics in system_scores.items():
            print(f"  ğŸ“Š {evaluator}è¯„ä»·å™¨:")
            
            total_scores = []
            for metric, score in metrics.items():
                grade = get_score_grade(score)
                if score is not None:
                    print(f"    {metric}: {score:.3f} {grade}")
                    total_scores.append(score)
                else:
                    print(f"    {metric}: {grade}")
            
            # è®¡ç®—è¯¥è¯„ä»·å™¨çš„æ€»ä½“è¯„åˆ†
            if total_scores:
                overall = sum(total_scores) / len(total_scores)
                overall_grade = get_score_grade(overall)
                print(f"    ğŸ“ˆ æ€»ä½“è¯„åˆ†: {overall:.3f} {overall_grade}")
            
            print()
        
        # è®¡ç®—ç³»ç»Ÿæ€»ä½“è¯„åˆ†
        all_system_scores = []
        for evaluator_metrics in system_scores.values():
            for score in evaluator_metrics.values():
                if score is not None:
                    all_system_scores.append(score)
        
        if all_system_scores:
            system_overall = sum(all_system_scores) / len(all_system_scores)
            system_grade = get_score_grade(system_overall)
            print(f"  ğŸ¯ {system}ç³»ç»Ÿæ€»è¯„åˆ†: {system_overall:.3f} {system_grade}")
        else:
            print(f"  ğŸ¯ {system}ç³»ç»Ÿæ€»è¯„åˆ†: âŒ æ— æœ‰æ•ˆè¯„åˆ†")
        
        print()
    
    # è¯„ä»·å™¨å¯¹æ¯”
    print("ğŸ“Š è¯„ä»·å™¨å¯¹æ¯”")
    print("-" * 40)
    
    for evaluator in evaluators:
        evaluator_all_scores = []
        
        for system in rag_systems:
            for col in df.columns:
                if col.startswith(f"{system}_{evaluator}_"):
                    scores = df[col].tolist()
                    valid_scores = [s for s in scores if s is not None and pd.notna(s)]
                    evaluator_all_scores.extend(valid_scores)
        
        if evaluator_all_scores:
            avg_score = sum(evaluator_all_scores) / len(evaluator_all_scores)
            grade = get_score_grade(avg_score)
            print(f"  {evaluator}: {avg_score:.3f} {grade} (åŸºäº{len(evaluator_all_scores)}ä¸ªè¯„åˆ†)")
        else:
            print(f"  {evaluator}: âŒ æ— æœ‰æ•ˆè¯„åˆ†")
    
    print()
    print("ğŸ“‹ è¯„åˆ†è¯´æ˜:")
    print("  ğŸ† ä¼˜ç§€ (0.9+)  ğŸ¥‡ è‰¯å¥½ (0.8+)  ğŸ¥ˆ ä¸­ç­‰ (0.7+)")
    print("  ğŸ¥‰ åŠæ ¼ (0.6+)  âŒ éœ€æ”¹è¿› (<0.6)")

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1:
        csv_file = sys.argv[1]
    else:
        csv_file = "results/multi_evaluation_results.csv"
    
    view_scores(csv_file)

if __name__ == "__main__":
    main()
